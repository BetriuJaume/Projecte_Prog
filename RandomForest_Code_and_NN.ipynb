{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RandomForest_Code and NN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPR5dz1GOA/6sBavPXobxDp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BetriuJaume/Projecte_Prog/blob/master/RandomForest_Code_and_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vXWMKWqPhhL",
        "outputId": "8e00e7c2-fdc8-4cfe-95ec-d5171398f508"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyreadstat in /usr/local/lib/python3.7/dist-packages (1.1.4)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from pyreadstat) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyreadstat) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyreadstat) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyreadstat) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyreadstat) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyreadstat\n",
        "import pyreadstat"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from sklearn.utils import resample\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "!pip install h2o\n",
        "import h2o\n",
        "from h2o.estimators import H2ORandomForestEstimator\n",
        "h2o.init()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "m5GxHc4bQAFi",
        "outputId": "7d9da09a-bde8-4c8f-9c6b-81b372b1d5ba"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: h2o in /usr/local/lib/python3.7/dist-packages (3.34.0.7)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from h2o) (0.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from h2o) (2.23.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from h2o) (0.8.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->h2o) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->h2o) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->h2o) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->h2o) (2021.10.8)\n",
            "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
              "<td>57 mins 11 secs</td></tr>\n",
              "<tr><td>H2O_cluster_timezone:</td>\n",
              "<td>Etc/UTC</td></tr>\n",
              "<tr><td>H2O_data_parsing_timezone:</td>\n",
              "<td>UTC</td></tr>\n",
              "<tr><td>H2O_cluster_version:</td>\n",
              "<td>3.34.0.7</td></tr>\n",
              "<tr><td>H2O_cluster_version_age:</td>\n",
              "<td>1 month and 4 days </td></tr>\n",
              "<tr><td>H2O_cluster_name:</td>\n",
              "<td>H2O_from_python_unknownUser_bojpcy</td></tr>\n",
              "<tr><td>H2O_cluster_total_nodes:</td>\n",
              "<td>1</td></tr>\n",
              "<tr><td>H2O_cluster_free_memory:</td>\n",
              "<td>3.166 Gb</td></tr>\n",
              "<tr><td>H2O_cluster_total_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_allowed_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_status:</td>\n",
              "<td>locked, healthy</td></tr>\n",
              "<tr><td>H2O_connection_url:</td>\n",
              "<td>http://localhost:54321</td></tr>\n",
              "<tr><td>H2O_connection_proxy:</td>\n",
              "<td>{\"http\": null, \"https\": null}</td></tr>\n",
              "<tr><td>H2O_internal_security:</td>\n",
              "<td>False</td></tr>\n",
              "<tr><td>H2O_API_Extensions:</td>\n",
              "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
              "<tr><td>Python_version:</td>\n",
              "<td>3.7.12 final</td></tr></table></div>"
            ],
            "text/plain": [
              "--------------------------  ------------------------------------------------------------------\n",
              "H2O_cluster_uptime:         57 mins 11 secs\n",
              "H2O_cluster_timezone:       Etc/UTC\n",
              "H2O_data_parsing_timezone:  UTC\n",
              "H2O_cluster_version:        3.34.0.7\n",
              "H2O_cluster_version_age:    1 month and 4 days\n",
              "H2O_cluster_name:           H2O_from_python_unknownUser_bojpcy\n",
              "H2O_cluster_total_nodes:    1\n",
              "H2O_cluster_free_memory:    3.166 Gb\n",
              "H2O_cluster_total_cores:    2\n",
              "H2O_cluster_allowed_cores:  2\n",
              "H2O_cluster_status:         locked, healthy\n",
              "H2O_connection_url:         http://localhost:54321\n",
              "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
              "H2O_internal_security:      False\n",
              "H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
              "Python_version:             3.7.12 final\n",
              "--------------------------  ------------------------------------------------------------------"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dades=pd.read_spss('EarlyLifeCovidPACIENTES V6 ID.sav')\n",
        "\n",
        "def canvi_tab(elem):\n",
        "  if(elem=='si (pasado o actual)'):\n",
        "    return 'yes'\n",
        "  if(elem=='nunca'):\n",
        "    return 'no'\n",
        "def canvi(elem):\n",
        "  if(elem=='si'):\n",
        "    return 'yes'\n",
        "  if(elem=='no'):\n",
        "    return 'no'\n",
        "def canvi_UCI(elem):\n",
        "  if(elem==1):\n",
        "    return 'Yes'\n",
        "  if(elem==0):\n",
        "    return 'No'\n",
        "def canvi_sex(elem):\n",
        "  if(elem=='mujer'):\n",
        "    return 'woman'\n",
        "  if(elem=='hombre'):\n",
        "    return 'man'\n",
        "\n",
        "dades['Tabaco_SIno']=dades['Tabaco_SIno'].apply(canvi_tab)\n",
        "dades['UCI']=dades['UCI'].apply(canvi_UCI)\n",
        "for columna in dades.columns[14:]:\n",
        "  dades[columna]=dades[columna].apply(canvi)\n",
        "dades['Gender']=dades['Gender'].apply(canvi_sex)\n",
        "dades['IUGR_calc']=dades['IUGR_calc'].apply(canvi_UCI)\n",
        "dades.columns=pd.Index(['ID', 'UCI', 'IUGR_missing', 'Age', 'Gender', 'Size', 'Weight',\n",
        "       'Size_mt', 'IMC', 'BW', 'BW_2500', 'percentil_birth', 'IUGR_calc',\n",
        "       'Tobacco_yes_no', 'Hipertension', 'Heart_diseases', 'DM', 'Dyslipidemia',\n",
        "       'Obesity', 'Kidney_disease', 'Autoimmune', 'Cancer', 'Thyroid', 'Infectious',\n",
        "       'Psychiatric'])"
      ],
      "metadata": {
        "id": "pmr0cur5QHSS"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dades_train = dades.sample(frac=0.8, random_state=25).drop('ID',axis=1)\n",
        "dades_test = dades.drop(dades_train.index).drop('ID',axis=1)"
      ],
      "metadata": {
        "id": "UjTfwCvGQKzx"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will design a function to caluculate the accuraccy of the models:"
      ],
      "metadata": {
        "id": "qv7T6QvnQgMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def precisions(reals,prediccions):\n",
        "  cont_Yes=0\n",
        "  cont_No=0\n",
        "  for i in range(len(reals)):\n",
        "    if (reals.iloc[i]==prediccions[i]) & (reals.iloc[i]=='Yes'):\n",
        "      cont_Yes=cont_Yes+1\n",
        "    if (reals.iloc[i]==prediccions[i]) & (reals.iloc[i]=='No'):\n",
        "      cont_No=cont_No+1\n",
        "  print('Precision for the Yes: '+str(cont_Yes/len(reals[reals=='Yes'])))\n",
        "  print('Precision for the No: '+str(cont_No/len(reals[reals=='No'])))\n",
        "  print('Total precision: '+str((cont_Yes+cont_No)/len(reals)))"
      ],
      "metadata": {
        "id": "R_LyO7wcQYtt"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we will create the upsampled training data to balance the dataset:"
      ],
      "metadata": {
        "id": "ORMBZKy3STLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dades_train_UCI_No=dades_train[dades_train['UCI']=='No']\n",
        "dades_train_UCI_Yes=dades_train[dades_train['UCI']=='Yes']\n",
        "dades_UCI_Yes_upsampled=resample(dades_train_UCI_Yes,replace=True,n_samples=len(dades_train_UCI_No),random_state=123)\n",
        "dades_train_upsampled=pd.concat([dades_train_UCI_No,dades_UCI_Yes_upsampled])"
      ],
      "metadata": {
        "id": "ZvH8jiP8SLrE"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " and here we will create the training data balanced with SMOTENC"
      ],
      "metadata": {
        "id": "rHo2RTwATHg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categ_indexes=[0,2,7,8]+list(range(10,dades_train.shape[1]-1))\n",
        "smot = SMOTENC(categorical_features=categ_indexes, random_state=123)\n",
        "dades_train_SMOTENC, dades_train_SMOTENC_UCI = smot.fit_resample(dades_train.drop('UCI',axis=1), dades_train['UCI'])\n",
        "dades_train_SMOTENC['UCI']=dades_train_SMOTENC_UCI"
      ],
      "metadata": {
        "id": "dTkNH0eDSmaQ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training of the Random Forest models from the library H2O"
      ],
      "metadata": {
        "id": "B-K0riuhTayu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the upsampling training dataset for training one model, the SMOTENC training dataset for training another model and then we will compare them"
      ],
      "metadata": {
        "id": "-uWXV5tETtT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dades_train_upsampled_h2o=h2o.H2OFrame(dades_train_upsampled)\n",
        "dades_train_SMOTENC_h2o=h2o.H2OFrame(dades_train_SMOTENC)\n",
        "predictors_upsampling=['BW_2500','Gender','Hipertension','Obesity','Age','IMC']   #h2o.H2OFrame(dades_train_upsampled).drop('UCI',axis=1).columns\n",
        "predictors_SMOTENC=['BW_2500','Cancer','DM','Dyslipidemia','Gender','Hipertension','Obesity','Psychiatric','Age']\n",
        "response='UCI'\n",
        "\n",
        "model_random_forest_upsampling = H2ORandomForestEstimator(ntrees=500,\n",
        "                                    max_depth=20,\n",
        "                                    min_rows=10,\n",
        "                                    seed=123,\n",
        "                                    mtries=-1)\n",
        "model_random_forest_SMOTENC = H2ORandomForestEstimator(ntrees=500,\n",
        "                                    max_depth=20,\n",
        "                                    min_rows=10,\n",
        "                                    seed=123,\n",
        "                                    mtries=-1)\n",
        "\n",
        "model_random_forest_upsampling=model_random_forest_upsampling.train(x=predictors_upsampling,\n",
        "                                                         y=response,\n",
        "                                                         training_frame=dades_train_upsampled_h2o)\n",
        "model_random_forest_SMOTENC=model_random_forest_SMOTENC.train(x=predictors_SMOTENC,\n",
        "                                                      y=response,\n",
        "                                                      training_frame=dades_train_SMOTENC_h2o)\n",
        "\n",
        "prediccions_random_forest_upsampling=model_random_forest_upsampling.predict(h2o.H2OFrame(dades_test).drop('UCI',axis=1))\n",
        "prediccions_random_forest_SMOTENC=model_random_forest_SMOTENC.predict(h2o.H2OFrame(dades_test).drop('UCI',axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ha37mGuuTm9d",
        "outputId": "5ae927d8-a38c-4ef0-b5ed-d62abf6bb137"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
            "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
            "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
            "drf prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
            "drf prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we have both models trained we can calculate our predictions"
      ],
      "metadata": {
        "id": "tn_txXz3ULeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediccions_random_forest_upsampling=model_random_forest_upsampling.predict(h2o.H2OFrame(dades_test).drop('UCI',axis=1))\n",
        "prediccions_random_forest_SMOTENC=model_random_forest_SMOTENC.predict(h2o.H2OFrame(dades_test).drop('UCI',axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0chpnlxT-6d",
        "outputId": "8b8b3a08-741f-4459-b0d4-bf35ecc6cee6"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
            "drf prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
            "drf prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And check the accuracy"
      ],
      "metadata": {
        "id": "bB-1Pt7eULD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediccions_random_forest_upsampling= prediccions_random_forest_upsampling['predict'].as_data_frame()\n",
        "prediccions_random_forest_upsampling=prediccions_random_forest_upsampling['predict'].tolist()\n",
        "\n",
        "prediccions_random_forest_SMOTENC= prediccions_random_forest_SMOTENC['predict'].as_data_frame()\n",
        "prediccions_random_forest_SMOTENC=prediccions_random_forest_SMOTENC['predict'].tolist()\n",
        "\n",
        "print('Upsampling:')\n",
        "precisions(dades_test['UCI'],prediccions_random_forest_upsampling)\n",
        "print('___________________________________')\n",
        "print('SMOTENC:')\n",
        "precisions(dades_test['UCI'],prediccions_random_forest_SMOTENC)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqukcHnAUDGY",
        "outputId": "cd72fe0b-856a-48ac-fa3c-63b4ada32f3a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upsampling:\n",
            "Precision for the Yes: 0.7272727272727273\n",
            "Precision for the No: 0.7647058823529411\n",
            "Total precision: 0.759493670886076\n",
            "___________________________________\n",
            "SMOTENC:\n",
            "Precision for the Yes: 0.7272727272727273\n",
            "Precision for the No: 0.6323529411764706\n",
            "Total precision: 0.6455696202531646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Design, training and hiperparameter adjusting of the Neural Network"
      ],
      "metadata": {
        "id": "Y89CAruMVxIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.utils.data as data_utils\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "m4mnwIm5VhKH"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have to do a first codification of the categorical predictors because Torch tensors only work with categorical values"
      ],
      "metadata": {
        "id": "wxYNXsl6Xr8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def codGender(elem):\n",
        "  if elem=='man':\n",
        "    return 1.\n",
        "  else:\n",
        "    return 0.\n",
        "def codUCI(elem):\n",
        "  if elem=='Yes':\n",
        "    return 1.\n",
        "  else:\n",
        "    return 0.\n",
        "def codBW(elem):\n",
        "  if elem=='BW normal':\n",
        "    return 0.\n",
        "  else:\n",
        "    return 1.\n",
        "def cod(elem):\n",
        "  if elem=='yes':\n",
        "    return 1.\n",
        "  else:\n",
        "    return 0.\n",
        "\n",
        "dades_cod_train=dades_train_upsampled.drop('IUGR_missing',axis=1).copy()\n",
        "dades_cod_test=dades_test.drop('IUGR_missing',axis=1).copy()\n",
        "\n",
        "for df in [dades_cod_train,dades_cod_test]:\n",
        "  df['UCI']=df['UCI'].apply(codUCI)\n",
        "  df['Gender']=df['Gender'].apply(codGender)\n",
        "  df['BW_2500']=df['BW_2500'].apply(codBW)\n",
        "  df['IUGR_calc']=df['IUGR_calc'].apply(codUCI)\n",
        "  for element in df.columns[11:]:\n",
        "    df[element]=df[element].apply(cod)\n",
        "\n",
        "target_train=torch.tensor(dades_cod_train['UCI'].values)\n",
        "features_train=torch.tensor(dades_cod_train.drop('UCI',axis=1).values)\n",
        "Dades_Tensor_train=TensorDataset(features_train,target_train)\n",
        "\n",
        "target_test=torch.tensor(dades_cod_test['UCI'].values)\n",
        "features_test=torch.tensor(dades_cod_test.drop('UCI',axis=1).values)\n",
        "Dades_Tensor_test=TensorDataset(features_test,target_test)\n",
        "\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "train_torch,val_torch=random_split(Dades_Tensor_train,[int(0.8*len(Dades_Tensor_train))+1,int(0.2*len(Dades_Tensor_train))],generator=torch.Generator().manual_seed(123))\n",
        "test_torch=Dades_Tensor_test\n",
        "\n",
        "train_torch1=DataLoader(train_torch,batch_size=10,shuffle=True)\n",
        "val_torch1=DataLoader(val_torch,batch_size=5,shuffle=True)\n",
        "test_torch1=DataLoader(test_torch,batch_size=5,shuffle=True)"
      ],
      "metadata": {
        "id": "Wm_T0rTSV_qB"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We design our net"
      ],
      "metadata": {
        "id": "wAx6sHuFY423"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.input_layer=nn.Linear(features_train.size()[1],14) #weights\n",
        "    #self.hidden1=nn.Linear(14,7)\n",
        "    #self.hidden2=nn.Linear(7,7)\n",
        "    #self.hidden3=nn.Linear(7,10)\n",
        "    #self.hidden4=nn.Linear(10,7)\n",
        "    self.output=nn.Linear(14,2)\n",
        "  \n",
        "  def forward(self, data): #activation functions, we will use the ReLu function\n",
        "    data=F.relu(self.input_layer(data))\n",
        "    #data=F.relu(self.hidden1(data))\n",
        "    #data=F.relu(self.hidden2(data))\n",
        "    #data=F.relu(self.hidden3(data))\n",
        "    #data=F.relu(self.hidden4(data))\n",
        "    data=self.output(data)\n",
        "    return F.log_softmax(data, dim=1)"
      ],
      "metadata": {
        "id": "6eiM_HotYrg4"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " and we train it with the **upsampling training dataset** and once we have the NN trained we will use the validation dataset to adjust the hiperparameter **rep**:"
      ],
      "metadata": {
        "id": "gnzJOG7gZpPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Accuracy_yes=[]\n",
        "Accuracy_no=[]\n",
        "\n",
        "network=Network()\n",
        "learn_rate=optim.Adam(network.parameters(), lr=0.0001)\n",
        "for rep in range(30):\n",
        "  for i in range(rep):\n",
        "    for data in train_torch1:\n",
        "      predictors, objectiu=data\n",
        "      network.zero_grad()\n",
        "      result=network(predictors.float())\n",
        "      loss=F.nll_loss(result,objectiu.long())  #loss=F.cross_entropy(result,objectiu.long())  # negative log likelihood loss\n",
        "      loss.backward()\n",
        "      learn_rate.step()\n",
        "    #print(loss)\n",
        "\n",
        "  network.eval() #we tell the network that we are not training anymore\n",
        "\n",
        "  correct_No=0\n",
        "  correct_Yes=0\n",
        "  total_No=0\n",
        "  total_Yes=0\n",
        "\n",
        "  with torch.no_grad(): #validation set to adjust the hiperparameters\n",
        "    for data in val_torch1:\n",
        "      predictors, objectiu=data\n",
        "      result=network(predictors.float())\n",
        "      for index, tensor_value in enumerate(result):\n",
        "        if(objectiu[index]==1):\n",
        "          total_Yes=total_Yes+1\n",
        "          if(torch.argmax(tensor_value)==objectiu[index]):\n",
        "            correct_Yes=correct_Yes+1\n",
        "        if(objectiu[index]==0):\n",
        "          total_No=total_No+1\n",
        "          if(torch.argmax(tensor_value)==objectiu[index]):\n",
        "            correct_No=correct_No+1\n",
        "\n",
        "  accuracy_Yes=correct_Yes/total_Yes\n",
        "  accuracy_No=correct_No/total_No\n",
        "\n",
        "  Accuracy_yes.append(accuracy_Yes)\n",
        "  Accuracy_no.append(accuracy_No)\n",
        "\n",
        "  print('Accuracy Yes '+str(accuracy_Yes)+' with rep='+str(rep))\n",
        "  print('Accuracy No '+str(accuracy_No)+' with rep='+str(rep))\n",
        "  print('_________________________________________________________')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btjdx9JcZoal",
        "outputId": "4aa9d130-fb0c-4562-c818-0de9234286af"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Yes 0.0 with rep=0\n",
            "Accuracy No 1.0 with rep=0\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.0 with rep=1\n",
            "Accuracy No 1.0 with rep=1\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.0 with rep=2\n",
            "Accuracy No 1.0 with rep=2\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.0 with rep=3\n",
            "Accuracy No 1.0 with rep=3\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.423728813559322 with rep=4\n",
            "Accuracy No 0.5416666666666666 with rep=4\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.4067796610169492 with rep=5\n",
            "Accuracy No 0.625 with rep=5\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.22033898305084745 with rep=6\n",
            "Accuracy No 0.7291666666666666 with rep=6\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.3898305084745763 with rep=7\n",
            "Accuracy No 0.6666666666666666 with rep=7\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.3559322033898305 with rep=8\n",
            "Accuracy No 0.6875 with rep=8\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.1864406779661017 with rep=9\n",
            "Accuracy No 0.7916666666666666 with rep=9\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.3389830508474576 with rep=10\n",
            "Accuracy No 0.7083333333333334 with rep=10\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.3389830508474576 with rep=11\n",
            "Accuracy No 0.6875 with rep=11\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.423728813559322 with rep=12\n",
            "Accuracy No 0.625 with rep=12\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.9661016949152542 with rep=13\n",
            "Accuracy No 0.1875 with rep=13\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.23728813559322035 with rep=14\n",
            "Accuracy No 0.875 with rep=14\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.5254237288135594 with rep=15\n",
            "Accuracy No 0.5416666666666666 with rep=15\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.8135593220338984 with rep=16\n",
            "Accuracy No 0.4166666666666667 with rep=16\n",
            "_________________________________________________________\n",
            "Accuracy Yes 1.0 with rep=17\n",
            "Accuracy No 0.22916666666666666 with rep=17\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.3898305084745763 with rep=18\n",
            "Accuracy No 0.8125 with rep=18\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.3898305084745763 with rep=19\n",
            "Accuracy No 0.8333333333333334 with rep=19\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.8135593220338984 with rep=20\n",
            "Accuracy No 0.5208333333333334 with rep=20\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.5254237288135594 with rep=21\n",
            "Accuracy No 0.8333333333333334 with rep=21\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.847457627118644 with rep=22\n",
            "Accuracy No 0.5208333333333334 with rep=22\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.711864406779661 with rep=23\n",
            "Accuracy No 0.6041666666666666 with rep=23\n",
            "_________________________________________________________\n",
            "Accuracy Yes 1.0 with rep=24\n",
            "Accuracy No 0.2708333333333333 with rep=24\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.6440677966101694 with rep=25\n",
            "Accuracy No 0.6666666666666666 with rep=25\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.6440677966101694 with rep=26\n",
            "Accuracy No 0.7083333333333334 with rep=26\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.847457627118644 with rep=27\n",
            "Accuracy No 0.4791666666666667 with rep=27\n",
            "_________________________________________________________\n",
            "Accuracy Yes 1.0 with rep=28\n",
            "Accuracy No 0.3541666666666667 with rep=28\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.9491525423728814 with rep=29\n",
            "Accuracy No 0.4166666666666667 with rep=29\n",
            "_________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will train our NN with the **SMOTENC training dataset**. First we make the codification of the categorical values as we did with the other one:"
      ],
      "metadata": {
        "id": "i7sAyJ2WahL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_col=dades_train_SMOTENC.pop('UCI')\n",
        "dades_train_SMOTENC.insert(0, 'UCI', first_col)\n",
        "dades_train_SMOTENC=dades_train_SMOTENC.sample(frac=1)\n",
        "\n",
        "dades_cod_train=dades_train_SMOTENC.drop('IUGR_missing',axis=1).copy()\n",
        "dades_cod_test=dades_test.drop('IUGR_missing',axis=1).copy()\n",
        "\n",
        "for df in [dades_cod_train,dades_cod_test]:\n",
        "  df['UCI']=df['UCI'].apply(codUCI)\n",
        "  df['Gender']=df['Gender'].apply(codGender)\n",
        "  df['BW_2500']=df['BW_2500'].apply(codBW)\n",
        "  df['IUGR_calc']=df['IUGR_calc'].apply(codUCI)\n",
        "  for element in df.columns[11:]:\n",
        "    df[element]=df[element].apply(cod)\n",
        "\n",
        "target_train=torch.tensor(dades_cod_train['UCI'].values)\n",
        "features_train=torch.tensor(dades_cod_train.drop('UCI',axis=1).values)\n",
        "Dades_Tensor_train=TensorDataset(features_train,target_train)\n",
        "\n",
        "target_test=torch.tensor(dades_cod_test['UCI'].values)\n",
        "features_test=torch.tensor(dades_cod_test.drop('UCI',axis=1).values)\n",
        "Dades_Tensor_test=TensorDataset(features_test,target_test)\n",
        "\n",
        "from torch.utils.data import random_split\n",
        "#train_torch,val_torch,test_torch=random_split(Dades_Tensor,[int(0.7*len(dades))+2,int(0.15*len(dades)),int(0.15*len(dades))],generator=torch.Generator().manual_seed(123))\n",
        "\n",
        "train_torch,val_torch=random_split(Dades_Tensor_train,[int(0.8*len(Dades_Tensor_train))+1,int(0.2*len(Dades_Tensor_train))],generator=torch.Generator().manual_seed(22))\n",
        "test_torch=Dades_Tensor_test\n",
        "\n",
        "train_torch1=DataLoader(train_torch,batch_size=10,shuffle=True)\n",
        "val_torch1=DataLoader(val_torch,batch_size=10,shuffle=True)\n",
        "test_torch1=DataLoader(test_torch,batch_size=10,shuffle=True)"
      ],
      "metadata": {
        "id": "WRZNqBx2ZiSj"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "and we train and validate the Neural Network:"
      ],
      "metadata": {
        "id": "NrgQhthdcsaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Accuracy_yes=[]\n",
        "Accuracy_no=[]\n",
        "\n",
        "network=Network()\n",
        "learn_rate=optim.Adam(network.parameters(), lr=0.0001)\n",
        "for rep in range(30):\n",
        "  for i in range(rep):\n",
        "    for data in train_torch1:\n",
        "      predictors, objectiu=data\n",
        "      network.zero_grad()\n",
        "      result=network(predictors.float())\n",
        "      loss=F.nll_loss(result,objectiu.long())  #loss=F.cross_entropy(result,objectiu.long())  # negative log likelihood loss\n",
        "      loss.backward()\n",
        "      learn_rate.step()\n",
        "    #print(loss)\n",
        "\n",
        "  network.eval() #we tell the network that we are not training anymore\n",
        "\n",
        "  correct_No=0\n",
        "  correct_Yes=0\n",
        "  total_No=0\n",
        "  total_Yes=0\n",
        "\n",
        "  with torch.no_grad(): #validation set to adjust the hiperparameters\n",
        "    for data in val_torch1:\n",
        "      predictors, objectiu=data\n",
        "      result=network(predictors.float())\n",
        "      for index, tensor_value in enumerate(result):\n",
        "        if(objectiu[index]==1):\n",
        "          total_Yes=total_Yes+1\n",
        "          if(torch.argmax(tensor_value)==objectiu[index]):\n",
        "            correct_Yes=correct_Yes+1\n",
        "        if(objectiu[index]==0):\n",
        "          total_No=total_No+1\n",
        "          if(torch.argmax(tensor_value)==objectiu[index]):\n",
        "            correct_No=correct_No+1\n",
        "\n",
        "  accuracy_Yes=correct_Yes/total_Yes\n",
        "  accuracy_No=correct_No/total_No\n",
        "\n",
        "  Accuracy_yes.append(accuracy_Yes)\n",
        "  Accuracy_no.append(accuracy_No)\n",
        "\n",
        "  print('Accuracy Yes '+str(accuracy_Yes)+' with rep='+str(rep))\n",
        "  print('Accuracy No '+str(accuracy_No)+' with rep='+str(rep))\n",
        "  print('_________________________________________________________')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TKLdkRrcnyq",
        "outputId": "f6da3128-5fab-4edd-db70-8b4f483779ef"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Yes 1.0 with rep=0\n",
            "Accuracy No 0.0 with rep=0\n",
            "_________________________________________________________\n",
            "Accuracy Yes 1.0 with rep=1\n",
            "Accuracy No 0.0 with rep=1\n",
            "_________________________________________________________\n",
            "Accuracy Yes 1.0 with rep=2\n",
            "Accuracy No 0.0 with rep=2\n",
            "_________________________________________________________\n",
            "Accuracy Yes 1.0 with rep=3\n",
            "Accuracy No 0.0 with rep=3\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.5777777777777777 with rep=4\n",
            "Accuracy No 0.27419354838709675 with rep=4\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.5555555555555556 with rep=5\n",
            "Accuracy No 0.3064516129032258 with rep=5\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.5333333333333333 with rep=6\n",
            "Accuracy No 0.3709677419354839 with rep=6\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.3333333333333333 with rep=7\n",
            "Accuracy No 0.6129032258064516 with rep=7\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.4 with rep=8\n",
            "Accuracy No 0.5161290322580645 with rep=8\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.2 with rep=9\n",
            "Accuracy No 0.7580645161290323 with rep=9\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.8666666666666667 with rep=10\n",
            "Accuracy No 0.03225806451612903 with rep=10\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.37777777777777777 with rep=11\n",
            "Accuracy No 0.5967741935483871 with rep=11\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.8666666666666667 with rep=12\n",
            "Accuracy No 0.14516129032258066 with rep=12\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.9333333333333333 with rep=13\n",
            "Accuracy No 0.14516129032258066 with rep=13\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.7111111111111111 with rep=14\n",
            "Accuracy No 0.532258064516129 with rep=14\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.4888888888888889 with rep=15\n",
            "Accuracy No 0.6935483870967742 with rep=15\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.9111111111111111 with rep=16\n",
            "Accuracy No 0.46774193548387094 with rep=16\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.9777777777777777 with rep=17\n",
            "Accuracy No 0.20967741935483872 with rep=17\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.9111111111111111 with rep=18\n",
            "Accuracy No 0.4838709677419355 with rep=18\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.26666666666666666 with rep=19\n",
            "Accuracy No 0.967741935483871 with rep=19\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.8888888888888888 with rep=20\n",
            "Accuracy No 0.6129032258064516 with rep=20\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.9777777777777777 with rep=21\n",
            "Accuracy No 0.3064516129032258 with rep=21\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.9333333333333333 with rep=22\n",
            "Accuracy No 0.46774193548387094 with rep=22\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.8444444444444444 with rep=23\n",
            "Accuracy No 0.6451612903225806 with rep=23\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.8666666666666667 with rep=24\n",
            "Accuracy No 0.6129032258064516 with rep=24\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.4222222222222222 with rep=25\n",
            "Accuracy No 0.8870967741935484 with rep=25\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.8444444444444444 with rep=26\n",
            "Accuracy No 0.6290322580645161 with rep=26\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.9555555555555556 with rep=27\n",
            "Accuracy No 0.43548387096774194 with rep=27\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.9555555555555556 with rep=28\n",
            "Accuracy No 0.3709677419354839 with rep=28\n",
            "_________________________________________________________\n",
            "Accuracy Yes 0.4 with rep=29\n",
            "Accuracy No 0.9193548387096774 with rep=29\n",
            "_________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally we will use te neural network trained by SMOTENC sample in the test dataset beacuse is the one that works better with the hyperparameter **rep**=29:"
      ],
      "metadata": {
        "id": "MOn8WrFZc9MX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct_No=0\n",
        "correct_Yes=0\n",
        "total_No=0\n",
        "total_Yes=0\n",
        "rep=25\n",
        "for data in test_torch1:\n",
        "  predictors, objectiu=data\n",
        "  result=network(predictors.float())\n",
        "  for index, tensor_value in enumerate(result):\n",
        "    if(objectiu[index]==1):\n",
        "      total_Yes=total_Yes+1\n",
        "      if(torch.argmax(tensor_value)==objectiu[index]):\n",
        "        correct_Yes=correct_Yes+1\n",
        "\n",
        "    if(objectiu[index]==0):\n",
        "      total_No=total_No+1\n",
        "      if(torch.argmax(tensor_value)==objectiu[index]):\n",
        "        correct_No=correct_No+1\n",
        "\n",
        "accuracy_Yes=correct_Yes/total_Yes\n",
        "accuracy_No=correct_No/total_No\n",
        "\n",
        "Accuracy_yes.append(accuracy_Yes)\n",
        "Accuracy_no.append(accuracy_No)\n",
        "\n",
        "print('Accuracy Yes '+str(accuracy_Yes)+' with rep='+str(rep))\n",
        "print('Accuracy No '+str(accuracy_No)+' with rep='+str(rep))\n",
        "print('_________________________________________________________')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0xwDtQAdPD8",
        "outputId": "aa9b2004-7ee1-410d-9ee3-cd2ab5b1a31d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Yes 0.0 with rep=25\n",
            "Accuracy No 0.9117647058823529 with rep=25\n",
            "_________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}